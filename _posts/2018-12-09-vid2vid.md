---
layout: post
title: vid2vid
categories:
- Research
tags:
- gan
---

[vid2vid](https://arxiv.org/pdf/1808.06601.pdf)提出了一种通用的video to video的生成框架，可以用于很多视频生成任务。常用的pix2pix没有对temporal dynamics建模，所以不能直接用于video synthesis。下面就pose2body对着[vid2vide code](https://github.com/NVIDIA/vid2vid)简单记录一二。

### 1. Network Architecture

#### 1.1 Sequential generator

作为Sequential G，输入有

![CompositeGenerator]()

![CompositeLocalGenerator]()

#### 1.2 Image discriminator

#### 1.2 Video discriminator

### 2. DataLoader

#### 2.1 PoseDataset

### 3. Training

### 4. Test