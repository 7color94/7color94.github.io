---
layout: post
title: Mask R-CNN
categories:
- Research
---

- Paper: [Mask R-CNN](https://arxiv.org/pdf/1703.06870.pdf)
- Source Code: [mmdetection](https://github.com/open-mmlab/mmdetection)

论文就不多讲了（一搜一大堆），这里主要记录读源代码时想记下来的东西。

### 1.网络结构

首先Mask R-CNN属于[TwoStageDetector](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/detectors/two_stage.py#L10)，结构组成有：

- neck：基于ResNet的[FPN](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/necks/fpn.py#L7)结构，主要用来提取5个不同level的feature maps（分辨率分别是原图的1/4，1/8，1/16，1/32和1/64），其中1/64的feature map是对1/32做stride=2的[max_pooling](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/necks/fpn.py#L118)得到。
- [rpn_head](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L15)：最经典的RPN了。。对5个不同level的feature maps[逐个](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L82)先过3x3的conv和relu，再经过不同的1x1 conv分别得到（N，3，H，W)的rpn_cls_score和（N，12，H，W）的rpn_bbox_pred，N为batch size，3是指每个点3个anchors（下面会提到）。
- [bbox_head](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/bbox_heads/convfc_bbox_head.py)：先用[bbox_roi_extractor](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/detectors/two_stage.py#L36)对proposals提取到7x7x256的roi特征，然后经过2层[shared fc](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/bbox_heads/convfc_bbox_head.py#L139)，再经过不同的1层fc分别得到81类的cls_score（cls branch）和bbox_pred（box branch）。
- [mask_head](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/bbox_heads/convfc_bbox_head.py#L7)：先用[mask_roi_extractor](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/detectors/two_stage.py#L41)提取得到14x14x256的roi特征，然后经过4层conv/deconv的小型FCN，最终得到28x28x80的mask map。

bbox_head和mask_head具体网络结构可以看paper的Figure 4。

### 2.数据加载

[CocoDataset](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py#L7)继承了[CustomDataset](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/custom.py#L14)。

这里主要是做了[random flip](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/custom.py#L198)和[random scale](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/custom.py#L199)。若想真正地开启random scale training的话，需要在[cfg](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L113)设置多个scale，目前支持“value”和“range”两种scale[采样](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/utils.py#L36)的方式，最后通过[pad](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/transforms.py#L40)确保scale后图片的长宽都能被32整除。

还有一个值得注意的问题是由于coco数据集图片的长宽不一致，所以把同一个batch但不同大小的图片cat一起送进torch的网络之前，会对小图做[pad](https://github.com/open-mmlab/mmcv/blob/master/mmcv/parallel/data_container.py#L18)。

### 3.训练阶段

下面进入[训练](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/detectors/two_stage.py#L78)。

#### 3.1 rpn_head

先用[AnchorGenerator](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/anchor/anchor_generator.py#L4)为每个level的feature map获取[anchors](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L155)，每个点3个（1：1，2：1，1：2），并进行anchor的[过滤](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L116)。

之后通过[MaxIoUAssigner](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L8)为每个anchor分配gt bbox或者background，原则是[阈值pos_iou_thr=0.7](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L58)和[最大iou](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L128)。然后[采样](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assign_sampling.py#L33)共[num=256](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L64)个正负anchors，正负比例最好是[1：1](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L65)，去训rpn。正anchor和对应的gt bbox之间的回归量通过[bbox2delta](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/transforms.py#L6)计算。

最终loss由cls和reg[组成](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L164)。

#### 3.2 bbox_head和mask_head

rpn_head和bbox_head、mask_head可以joint training。在计算好rpn_head的loss之后，rpn_head进入“前向测试”状态，获取bbox_head和mask_head需要的[proposals](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L176)，具体来说：rpn_head还是先生成anchors，然后根据rpn_cls_score去[排序](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L222)anchors，选择前[cfg.nms_pre=2000](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L91)个anchors，把回归量rpn_bbox_pred[计算](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L228)在anchors上得到proposals，再经由[nms](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/rpn_heads/rpn_head.py#L237)（nms_thr=0.7）得到最多2000个proposals。

拿到proposals之后，rcnn根据之前的rpn的规则（这里[pos_iou_thr=0.5](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L75)）为每个proposals分配gt bbox，并采样[num=512](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L81)个正负proposals，正负比例[1：3](https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn_r50_fpn_1x.py#L82)。

有了proposals，后面不管什么head/branch，就简单了。

bbox_head针对正负proposals，训练分类（81类）和回归任务（box refine）。

mask_head只针对正proposals准备对应的[mask gt](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/mask/mask_target.py#L29)，去训练mask任务。

### 4.测试阶段

略