---
layout: post
title: pix2pix和CycleGAN
categories:
- Research
tags:
- gan
---

### 1. [pix2pix](https://arxiv.org/pdf/1611.07004.pdf)

#### 1.1 网络结构

**Generator**

遵循Encoder-Decoder，先下采样，再上采样回到input的尺寸，conv后面一般都跟bn、relu。常见Generator的结构有：ResnetGenerator、UnetGenerator（skip-layer）。具体的网络结构细节可以看[代码](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py)。

**Discriminator**

Discriminator会判断input中的每个N x N的patch是real还是fake，也就是所说的[PatchGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/39)。

#### 1.2 前向

real_A过Generator得到fake_B

#### 1.3 反向

先定义loss：

- D的目的是区分real和fake，所以当输入(real_A, real_B)时，D的输出得分尽量高，当输入(real_A, fake_B)时，D的输出得分尽量低
- G的目的是欺骗D，即当输入(real_A, fake_B)时，D的输出得分尽量高。另外，G的另外一个监督loss是让fake_B尽量接近real_B，即fake_B和real_B之间挂一个l1 loss

反向传播的时候先固定G优化D，再固定D优化G，具体可以看[代码](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/pix2pix_model.py)。

#### 1.4 Image pool

Image pool存放一定数量的(real_A, fake_B)对，帮助D去记忆历史信息，而不仅仅是当前迭代的一对。

### 2. [pix2pixHD](https://arxiv.org/pdf/1711.11585.pdf)

先前的的pix2pix生成的image分辨率为256 x 256，pix2pixHD将生成分辨率提高到了2048 x 1024。

#### 2.1 网络结构

**Coarse-to-fine Generator**

生成器由两部分组成：Global generator network和Local enhancer network，两个network均是先上采样后下采样的架构。

- Global采用的pix2pix中的ResnetGenerator
- Local分辨率是Global的4x，Local部分先下采样得到的feature map和Global上采样的feature map融合，去做Local的上采样步骤，得到最终G的输出

Local数量可以增加，每增加一个，分辨率x4，一般设为1个。

**Multi-scale discriminator**

判断器由三个同样网络结构的子判别器组成，每个子判别器的input分别是三种递减的分辨率。

具体网络结构细节可以看[代码](https://github.com/NVIDIA/pix2pixHD/blob/master/models/networks.py)。

#### 2.2 反向

pix2pixHD修改了pix2pix的loss：

- D的目的是区分real和fake，所以当输入(real_A, real_B)时，D的输出得分尽量高，当输入(real_A, fake_B)时，D的输出得分尽量低
- G的目的是欺骗D，即当输入(real_A, fake_B)时，D的输出得分尽量高。另外，G生成fake_B经过D得到的N层feature map要和real_B的尽可能相似，这是feature matching loss。G生成fake_B经过VGG得到的N层feature map要和real_B的尽可能相似（l1 loss），这是perceptual loss。

### 3. [CycleGAN]()